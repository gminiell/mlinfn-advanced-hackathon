{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25a106c",
   "metadata": {},
   "source": [
    "# **Lung Segmentation on Chest X-Ray images with U-Net**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e62450",
   "metadata": {},
   "source": [
    "Chest X-Ray (CXR) imaging is a radiographic procedure that produces 2D images of the chest. When we want to analyze the lungs on this kind of images it is important to delete the unuseful information that may be contained in the image. A typical CXR looks like this:\n",
    "\n",
    "<center><img src=\"images/P_3_190_org.png\" alt=\"fishy\" class=\"bg-primary mb-1\" width=\"500px\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12a010",
   "metadata": {},
   "source": [
    "It is clear that there are many pixels that do not belong to lungs. So it is important to segment the lungs. In this exercise you will learn how to build, train and test a U-Net for lung segmentation. The network we are going to implement can be easly adapted to any other segmentation problem. So, let's see together what a U-Net is.\n",
    "U-net (cita ronnerberger) is a Fully Convolutional Neural Network (FCNN) and it is the state-of-the-art algorithm for medical segmentation. The term FCNN means that there are not dense layers (Multi-Layer Perceptron) at the end of the Network. Just to let you understand the difference:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267e1ef",
   "metadata": {},
   "source": [
    "- Suppose we have a standard Convolutional Neural Network for binary classification of images. We expect that the newtork architecture is made by several Convolutional, Pooling or Strided Convolutional layers, activation layers and so on. At a certain point of the architecture, we flatten the input by using a simple flattening or a Global Average Pooling for example. Once we reduced the size of the tensor to one dimension, we use dense layer to let our CNN classify the input images:\n",
    "\n",
    "<center><img src=\"./images/cnnfull2sfondo.gif\" alt=\"\" class=\"bg-primary mb-1\" width=\"700px\"></center>\n",
    "\n",
    "\n",
    "- In a Fully Convolutional Neural Network (FCNN), we perform a pixel-wise classification: image segmentation means to give to each pixel a class (in our case lung or background). The structure of the U-Net mirrors the structure of an autoencoder: the left part, also called compression path, is an encoder that compress the information with a CNN and the right part, called decompression path, is a decoder that upsample the encoded information in order to return an image with the same size of the input one. However, there are important differences between autoencoder and U-Nets. What are the differences?\n",
    "\n",
    "<center><img src=\"./images/unet_lung.png\" alt=\"\" class=\"bg-primary mb-1\" width=\"700px\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993df607-bfe2-4218-a336-27d2677c5510",
   "metadata": {},
   "source": [
    "In this exercise, you will learn to build, train and evaluate a CNN for lung segmentation on Chest X-Ray images. Moreover, you will be introduced to a possible structure of a such complex network. In fact, we won't use a single jupyter notebook to develop the code but we will see many parts of the training framework.\n",
    "\n",
    "Note: the images have already been pre-processed since their pre-processing requires time (about 2 hours). \n",
    "For your knowledge, the datasets we are going to use were collected to study tuberculosis. These datasets contain Chest X-Ray images and lung masks. The first\n",
    "one is the Shenzhen dataset, containing CXR images acquired as part of the routine care at Shenzhen Hospital (Guangdong Medical College, China) and released in JPEG format. There are 340 normal X-Rays and 275 abnormal X-Rays showing various manifestations of tuberculosis. The second one is the Montgomery dataset, which has\n",
    "been collected in collaboration with the Department of Health and Human Services, Montgomery County, Maryland, USA. The set contains 138 frontal chest X-Rays from Montgomery County‚Äôs Tuberculosis screening program, of which 80 are normal cases and 58 are cases with manifestations of TB. \n",
    "\n",
    "We aggregated the two datasets and pre-processed the images this way:\n",
    "- images underwent a contrast stretching between their 5ùë°‚Ñé and 95ùë°‚Ñé percentile and normalized. \n",
    "- some images present black borders, we crop and resized them to 256x256 size.\n",
    "\n",
    "In this exercise, we do not apply data augmentation because it will increase training time. You can develop your data augmentation in real-time during training as a further advancement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4219c8b",
   "metadata": {},
   "source": [
    "The software has to have this structure:\n",
    "- [a datagenerator ](Data_Generator/DataGenerator.ipynb)\n",
    "- [the architecture](UNet_Arch/UNET_architecture.ipynb)\n",
    "- [the loss and metrics](Loss_Metrics/LossMetrics.ipynb)\n",
    "- [the training module](./Train_UNET.ipynb)\n",
    "- [the inference and evaluation module](./Predict_UNet.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb5b36e-d960-49bf-9f0b-93916706ca59",
   "metadata": {},
   "source": [
    "# DATA GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa63182e-2856-485c-93b7-2097b5092b91",
   "metadata": {},
   "source": [
    "When we deal with a small amount of data we can use different ways to upload the data and give them as input to a Neural Network. If the data set is small enough, it can be loaded in a numpy array. When we deal with images, sometimes it is not possible to use this modality because we will saturate the RAM. For this reason we can use a data generator based on the Keras class Sequence to load only one batch per iteration instead of loading the entire dataset at once.\n",
    "\n",
    "In Keras it is possible to use a simple built in generator, called  [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator), which is a generator that that can be used for classification task. We saw the functioning of such function in the last editions of the ML-INFN Hackathon.\n",
    "\n",
    "It may happen that our data cannot be read with the ImageDataGenerator function or that we want to train an algorithm for tasks like regression or segmentation.\n",
    "In this [notebook](Data_Generator/DataGenerator.ipynb) you will see a customized data generator for segmentation.\n",
    "\n",
    "The goal of this part of the exercise is to broadly understand its functioning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cde929-519e-450f-bf54-b4e01f0a1c0d",
   "metadata": {},
   "source": [
    "# THE ARCHITECTURE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
